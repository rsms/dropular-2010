> **Note:** The following instructions assume you are running a local "out-of-the-box" couchdb server.

# Design

Dropular consists of two key-value databases:

- **users** -- houses all info about users (username, email, following, etc)
- **drops** -- houses all drops

As a database can be atomically snapshotted, we need to keep any data which might cause problems when out of sync to live inside the same database. This poses some obvious problems (i.e. a user creating a drop), but by listing the databases in a prioritized list, we can agree on where to expect relations to break or data to be partial:

1. users
2. drops

Now, when taking snapshots (replicating), just walk the list from **bottom up** -- the later the replication happens, the more complete the data of that database will be.

> **Discussion:** To further explain why this is importnat, let's imagine we do the reverse -- snapshot users before we snapshot drops. First this happens: we take a snapshot of users and start waiting for the server to build our snapshot, during this time a new user registers and creates a new drop. The user will not be part of the replication, as the snapshot has already been taken, *but the drop will*. Later, we also snapshot the drops database and we have one drop which has been created by a non-existing user. However, the reverse would be fine -- a user existing but have not created a drop. That's why we replicate the *weakest data* (or "most distant") data first.

When taking snapshots (replicating) you should make sure to perform replications in parallel rather than in a sequence. That will minimize the risk of broken relations between snapshots.

Each database exists of *schema-free entities* which can be though of as regular documents on a computer. They might be empty or contain some set of information. However, these "documents" are structured data (JSON) so we know where to look for a certain hunk of information.


## Design of the users database

The user database houses *users* including related information. Keys in this database are prefixed in order to allow future expansion (having sidecar data synchronized with user data, providing consistency in snapshots, during backup and between reads and writes).

A *user* entity is prefixed with `"user-"` and consists of the following data:

    "user-foo" => {
      "username":     "Foo",
      "email":        "foo@bar.com",
      "created":      1232854416321,
      "modified":     1267348334563,
      "passhash":     "d2115e39d4fe47007a03c3f6a02812e5bf4497c5",
      "following":    ["johndoe", "zorro"],
      "invite_quota": 958,
      "real_name":    "Foo Barson",
      "url":          "http://bar.com",
      "muted_users":  ["goopymart", "thonk", "greatsuccess"],
      "about":        "I'm a test dummy and I like it."
    }

There should not be any empty (false, null or undefined) fields in a user struct as a missing field means the same as "empty", thus not all of the fields above might exist for a given user.

The `passhash` is calculated as follows and is never sent in plain text:

    BASE-16( SHA-1( username ":" password ) )

### Authentication

Authentication is done over the standard oui client-server communication.

1. Client sends `GET /session/sign-in` to the server.
2. Server responds with a one-time valid nonce `auth_nonce`, actual username (might be unicode) and a session id.
3. Client calculates an appropriate response based on the `auth_nonce`, the actual username and password. See Figure 1. below.
4. Client sends the calculated response to `POST /session/sign-in`.
5. Server responds with `200 OK` containing a complete user structure and an `auth_token`, if credentials checked out. Otherwise `401 Unauthorized` is returned together with an explanation in the body. In this case of auth failure, steps 1 to 5 can be repeated.

**Figure 1.** Client's calculation of auth challenge response:

    passhash      = BASE16( SHA1( username ":" password ) )
    auth_response = BASE16( SHA1_HMAC( auth_nonce, passhash ) )

The `auth_token` returned in step 5 will be saved by the client (persistently) and sent with every consecutive request together with `auth_user` and `sid`. The `auth_user` and `auth_token` information can be used to transparently re-authenticate a user on any backend (thus enabling seamless backend failover). The `auth_token` is generated by the server and is an opaque piece of data constructed as illustrated by Figure 2.

**Figure 2.** `auth_token` construction:

    authToken    = ts ":" token
    ts           = BASE-36( TIME-NOW )
    token        = BASE-62( SHA1-HMAC( userSecret, serverSecret ":" ts ) )
    userSecret   = <user-specific data, e.g. a shadow>
    serverSecret = <constant data>


### Legacy data

Any user which was migrated from the old site will have the key "legacy" with a structure like this:

    "user-foo" => {
      "email":        "foo@bar.com",
      ...
      "legacy": {
        "id":           1234,
        "passhash":     "$1$jdj20dru$mBpFtOCxUNYpWh1n.bUhR0",
        "icon":         "foo-bar_no-semantics.here.jpg"
      },
    }

This data is used when transitioning a user into the new system (like password transfer).

As soon as a user has transitioned into a regular user the "legacy" structure can be removed as it does no longer serve any purpose.


## Design of the drops database

The drops database consists only of drops, keyed by their id.

    "iAXTWJkVlxW2ozFAwW83bN3oil0" => {
      "url":      "http://bar.com/finger/fashion/fingertip-shoes.jpg",
      "origin":   "http://www.foundshit.com/finger-tip-shoe-fashion/",
      "tags":     ["shoes", "fashion"],
      "title":    "Finger Tip Fashion \u00bb Funny, Bizarre, Amazing Pictures",
      "desc":     "Crazy little shoe for fingers",
      "disabled": true,
      "nsfw":     true,
      "users": {
        "foo": [1258195680123, 2],
        "someuser": [1258195681123, 1],
        "mrtroll": [1258195682123, 1]
      },
      "image": {
        "format": "JPEG",
        "width": 489,
        "height": 720,
        "depth": 8
      }
    }

Just as with user entities, drop entities might not contain all the fields illustrated above.

Description of fields in a "drop" entitity:

- **url** -- url to the image this drop represents. Should always exist.
- **origin** -- url to the document which contained the image. Might be missing if same as **url**.
- **tags** -- a simple list of unique tags without any apparent order.
- **title** -- an optional title.
- **desc** -- optional description.
- **disabled** -- if set and true, this drop has been disabled and should not be presented to users.
- **nsfw** -- if set and true, this drop has been classed as "not safe for work", probably containing something nasty. These drops should not be displayed to users who only want "safe" content.
- **users** -- see detailed description further down this document.

The `id` is calculated like this:

    id = BASE-62( SHA-1( url ) )


### "users" struct

The `users` key points to a structure mapping users to time and score. Each entry in the `users` struct is itself a list:

    string username => [ int timestamp, int score ]

- **timestamp** -- when the user dropped this drop. All timestamps are in UTC with millisecond precision.
- **score** -- the score this drop is worth (calculated from the users own score at the time of dropping).

Creation time of a drop can be inferred from this struct by finding the lowest timestamp value.

### Drop identifiers

Drop ids are constructed as follows:

    BASE-62( SHA-1( url ) )

- Drops are unique per absolute URL (to the image).
- We can easily perform a lookup from a URL.
- No need for UUID generation or sequential counters.

Drop data is stored in the Amazon S3 bucket `static.dropular.net` with a prefix and hiearchy namespacing:

    "drops/" type "/" <id[0]> "/" <id[1..2]> "/" <id[3..]> "." original-suffix

Examples:

    url  => http://therewasrain.com/gvi7bukvlr_402_hedi_slimane.jpg
    id   => 8TcklMBAFlTkQNzszPm6HfFhDaY
    data => drops/images/8/Tc/klMBAFlTkQNzszPm6HfFhDaY.jpg
    
    url  => http://www.codeproject.com/KB/web-image/ASCIIArt/ASCIIArt2.gif
    id   => trISBhp3gwu9eCrbkGZMHLYHj3i.gif
    data => drops/images/t/rI/SBhp3gwu9eCrbkGZMHLYHj3i.gif

# Setting up a database
## Creating a new database for development

1) Create the databases

    $ curl -X PUT http://127.0.0.1:5984/dropular-{users,drops}

2) Create some test data

    $ head -n 100 users.json | tail -n 10 > sample-users.json
    $ head -n 12000 drops.json | tail -n 100 > sample-drops.json

3) Load views

    $ node import-docs.js 127.0.0.1:5984/dropular-users views/users-*.json
    $ node import-docs.js 127.0.0.1:5984/dropular-drops views/drops-*.json

4) Load test data

    $ node import-batch.js 127.0.0.1:5984/dropular-users sample-users.json
    $ node import-batch.js 127.0.0.1:5984/dropular-drops sample-drops.json

You should now have a setup which you can play around with.

To setup a production instance, you should only perform step 1 and then replicate from a live CouchDB instance. Alternatively, create a SSH tunnel:

    $ ssh -L5985:127.0.0.1:5984 dropular.net
    $ curl -X PUT http://127.0.0.1:5985/dropular-{users,drops}
    $ curl -iX POST -u dropular:uDxCLqiig1Nk -d @views/drops-drops.json \
      127.0.0.1:5985/dropular-drops
    $ ...

## Copying an existing database

In most cases you probably want to pull down a copy of the live database. Doing so is simple.

First, make sure you have created the local databases (see "Creating a development database", step 1), then perform a *replication*:

    $ curl -vX POST http://127.0.0.1:5984/_replicate -d\
      '{"source":"http://remote.server:5984/dropular-drops",\
      "target":"dropular-drops"}' &
    
    $ curl -vX POST http://127.0.0.1:5984/_replicate -d\
      '{"source":"http://remote.server:5984/dropular-users",\
      "target":"dropular-users"}'

> **Discussion:** It is important you replicate data in the above order (first drops, then users) since the act of replication takes an "atomic snapshot" of the database (also make sure to perform the two queries in parallel if possible). There is a possibility a new user regiestered and created a drop while we are waiting for the "drops" replication to complete. The local replica would be broken, since there would exist drops made by users who does not exist in the users database.

